{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "union and unionAll  transformation are used to merge two or more dataframe of same structure and schema,\n",
    "it return the new datframe withh all rows from two datframe regardless of duplicate data i:e they do not remove duplicate rows\n",
    "\n",
    "to remove duplicate can use distinct() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-27E2FOUT:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Union and unionAll</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x27c39c23430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Union and unionAll').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1=[(1,'Maheer',2000),(2,'Wafa',30000),(3,'Asi',3000),(4,'Tonny',3000)]\n",
    "schema1=['id','name','salary']\n",
    "df1=spark.createDataFrame(data1,schema1)\n",
    "df1.printSchema()\n",
    "# df1.show()\n",
    "\n",
    "data2=[(5,'ram',5000),(6,'shyam',30000)]\n",
    "schema2=['id','name','salary']\n",
    "df2=spark.createDataFrame(data2,schema2)\n",
    "df2.printSchema()\n",
    "# df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging two dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3=df1.union(df2)\n",
    "df3.printSchema()\n",
    "# df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unionAll also work same as union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method union in module pyspark.sql.dataframe:\n",
      "\n",
      "union(other: 'DataFrame') -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Return a new :class:`DataFrame` containing the union of rows in this and another\n",
      "    :class:`DataFrame`.\n",
      "    \n",
      "    .. versionadded:: 2.0.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : :class:`DataFrame`\n",
      "        Another :class:`DataFrame` that needs to be unioned.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrame`\n",
      "        A new :class:`DataFrame` containing the combined rows with corresponding columns.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.unionAll\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This method performs a SQL-style set union of the rows from both `DataFrame` objects,\n",
      "    with no automatic deduplication of elements.\n",
      "    \n",
      "    Use the `distinct()` method to perform deduplication of rows.\n",
      "    \n",
      "    The method resolves columns by position (not by name), following the standard behavior\n",
      "    in SQL.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Example 1: Combining two DataFrames with the same schema\n",
      "    \n",
      "    >>> df1 = spark.createDataFrame([(1, 'A'), (2, 'B')], ['id', 'value'])\n",
      "    >>> df2 = spark.createDataFrame([(3, 'C'), (4, 'D')], ['id', 'value'])\n",
      "    >>> df3 = df1.union(df2)\n",
      "    >>> df3.show()\n",
      "    +---+-----+\n",
      "    | id|value|\n",
      "    +---+-----+\n",
      "    |  1|    A|\n",
      "    |  2|    B|\n",
      "    |  3|    C|\n",
      "    |  4|    D|\n",
      "    +---+-----+\n",
      "    \n",
      "    Example 2: Combining two DataFrames with different schemas\n",
      "    \n",
      "    >>> from pyspark.sql.functions import lit\n",
      "    >>> df1 = spark.createDataFrame([(\"Alice\", 1), (\"Bob\", 2)], [\"name\", \"id\"])\n",
      "    >>> df2 = spark.createDataFrame([(3, \"Charlie\"), (4, \"Dave\")], [\"id\", \"name\"])\n",
      "    >>> df1 = df1.withColumn(\"age\", lit(30))\n",
      "    >>> df2 = df2.withColumn(\"age\", lit(40))\n",
      "    >>> df3 = df1.union(df2)\n",
      "    >>> df3.show()\n",
      "    +-----+-------+---+\n",
      "    | name|     id|age|\n",
      "    +-----+-------+---+\n",
      "    |Alice|      1| 30|\n",
      "    |  Bob|      2| 30|\n",
      "    |    3|Charlie| 40|\n",
      "    |    4|   Dave| 40|\n",
      "    +-----+-------+---+\n",
      "    \n",
      "    Example 3: Combining two DataFrames with mismatched columns\n",
      "    \n",
      "    >>> df1 = spark.createDataFrame([(1, 2)], [\"A\", \"B\"])\n",
      "    >>> df2 = spark.createDataFrame([(3, 4)], [\"C\", \"D\"])\n",
      "    >>> df3 = df1.union(df2)\n",
      "    >>> df3.show()\n",
      "    +---+---+\n",
      "    |  A|  B|\n",
      "    +---+---+\n",
      "    |  1|  2|\n",
      "    |  3|  4|\n",
      "    +---+---+\n",
      "    \n",
      "    Example 4: Combining duplicate rows from two different DataFrames\n",
      "    \n",
      "    >>> df1 = spark.createDataFrame([(1, 'A'), (2, 'B'), (3, 'C')], ['id', 'value'])\n",
      "    >>> df2 = spark.createDataFrame([(3, 'C'), (4, 'D')], ['id', 'value'])\n",
      "    >>> df3 = df1.union(df2).distinct().sort(\"id\")\n",
      "    >>> df3.show()\n",
      "    +---+-----+\n",
      "    | id|value|\n",
      "    +---+-----+\n",
      "    |  1|    A|\n",
      "    |  2|    B|\n",
      "    |  3|    C|\n",
      "    |  4|    D|\n",
      "    +---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df1.union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method unionAll in module pyspark.sql.dataframe:\n",
      "\n",
      "unionAll(other: 'DataFrame') -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Return a new :class:`DataFrame` containing the union of rows in this and another\n",
      "    :class:`DataFrame`.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : :class:`DataFrame`\n",
      "        Another :class:`DataFrame` that needs to be combined\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrame`\n",
      "        A new :class:`DataFrame` containing combined rows from both dataframes.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This method combines all rows from both `DataFrame` objects with no automatic\n",
      "    deduplication of elements.\n",
      "    \n",
      "    Use the `distinct()` method to perform deduplication of rows.\n",
      "    \n",
      "    :func:`unionAll` is an alias to :func:`union`\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df1.unionAll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
